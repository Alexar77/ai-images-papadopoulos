# Deep Learning Exercises - Computer Vision Tasks

Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· 5 Î±ÏƒÎºÎ®ÏƒÎµÏ‰Î½ Î²Î±Î¸Î¹Î¬Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ Î³Î¹Î± Computer Vision Î¼Îµ PyTorch

## ğŸ“ Î”Î¿Î¼Î® Project

```
ai-images/
â”‚
â”œâ”€â”€ ğŸ“‚ Unified Utilities (4 files)
â”‚   â”œâ”€â”€ cifar_data_loaders.py        # CIFAR-10 & CIFAR-100 data loading
â”‚   â”œâ”€â”€ pet_data_loaders.py          # Oxford Pet (classification & detection)
â”‚   â”œâ”€â”€ training_utils.py            # All trainers (Classification, Segmentation, Detection)
â”‚   â””â”€â”€ visualization_utils.py       # All plotting & report generation
â”‚
â”œâ”€â”€ ğŸ“‚ Exercise #1: CIFAR-100 Classification (Vanilla CNN)
â”‚   â”œâ”€â”€ ex1_vanilla_cnn.py           # Custom 4-layer CNN architecture
â”‚   â”œâ”€â”€ ex1_main_experiments.py      # Hyperparameter comparison experiments
â”‚   â”œâ”€â”€ ex1_quick_experiment.py      # Quick test script
â”‚   â””â”€â”€ ex1_analyze_results.py       # Results analysis tool
â”‚
â”œâ”€â”€ ğŸ“‚ Exercise #2: Transfer Learning (Oxford Pet)
â”‚   â”œâ”€â”€ ex2_transfer_learning_models.py      # Pretrained models (ResNet, VGG, EfficientNet)
â”‚   â””â”€â”€ ex2_transfer_learning_experiments.py # Transfer learning experiments
â”‚
â”œâ”€â”€ ğŸ“‚ Exercise #3: Semantic Segmentation (SBD)
â”‚   â”œâ”€â”€ ex3_sbd_data_loader.py       # SBD dataset with 21 Pascal VOC classes
â”‚   â”œâ”€â”€ ex3_unet_model.py            # U-Net architecture
â”‚   â””â”€â”€ ex3_segmentation_experiments.py # Segmentation experiments
â”‚
â”œâ”€â”€ ğŸ“‚ Exercise #4: Object Detection (Oxford Pet)
â”‚   â”œâ”€â”€ ex4_detection_model.py       # Faster R-CNN (ResNet50/MobileNet)
â”‚   â””â”€â”€ ex4_detection_experiments.py # Detection experiments
â”‚
â”œâ”€â”€ ğŸ“‚ Exercise #5: CNN vs Transformer (CIFAR-10)
â”‚   â”œâ”€â”€ ex5_cnn_models.py            # VGG, ResNet18, ResNet50
â”‚   â”œâ”€â”€ ex5_vit_model.py             # Vision Transformer (from scratch)
â”‚   â””â”€â”€ ex5_comparative_experiments.py # Comparative study
â”‚
â”œâ”€â”€ requirements.txt                  # Dependencies
â””â”€â”€ README.md                         # This file
```

## ğŸ¯ Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î‘ÏƒÎºÎ®ÏƒÎµÏ‰Î½

### Î†ÏƒÎºÎ·ÏƒÎ· #1: Vanilla CNN Î³Î¹Î± CIFAR-100
**Dataset**: CIFAR-100 (100 classes, 50K train, 10K test)  
**Task**: Image classification  
**Model**: Custom 4-layer CNN (964K parameters)  
**Experiments**: Loss functions, optimizers, learning rates (9 total)  
**Best Result**: 33.43% test accuracy (LR=0.1, SGD)

```
Architecture: Input(3Ã—32Ã—32) â†’ Convâ†’PoolÃ—4 â†’ FCâ†’Dropout â†’ Output(100)
Parameters: 964,516 trainable
```

### Î†ÏƒÎºÎ·ÏƒÎ· #2: Transfer Learning
**Dataset**: Oxford-IIIT Pet (37 breeds, 7K images)  
**Task**: Image classification with pretrained models  
**Models**: ResNet18/50, AlexNet, VGG16, EfficientNet-B0  
**Experiments**: Architecture comparison, frozen vs fine-tuned, learning rates  
**Expected**: 85-92% test accuracy

### Î†ÏƒÎºÎ·ÏƒÎ· #3: Semantic Segmentation
**Dataset**: SBD - Semantic Boundaries Dataset (21 Pascal VOC classes)  
**Task**: Pixel-level segmentation  
**Model**: U-Net (encoder-decoder with skip connections)  
**Experiments**: Model sizes (base channels: 32/64/128), optimizers, learning rates  
**Metrics**: Pixel Accuracy, Mean IoU  
**Expected**: 40-75% mIoU

```
U-Net Architecture: Encoder (4 down) â†’ Bottleneck â†’ Decoder (4 up + skip connections)
```

### Î†ÏƒÎºÎ·ÏƒÎ· #4: Object Detection
**Dataset**: Oxford-IIIT Pet (37 breeds)  
**Task**: Object detection with bounding boxes  
**Model**: Faster R-CNN with FPN (ResNet50/MobileNet backbone)  
**Experiments**: Backbones, optimizers, learning rates (8 total)  
**Metrics**: Training loss components (classifier, box regression, RPN)  
**Expected**: Final loss ~0.4-0.7

### Î†ÏƒÎºÎ·ÏƒÎ· #5: Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· CNN vs Transformer
**Dataset**: CIFAR-10 (10 classes, 60K images)  
**Task**: Comparative study of architectures  
**CNN Models**: VGG11, ResNet18, ResNet50 (32Ã—32 images)  
**Transformer Models**: ViT-Tiny, ViT-Small (224Ã—224 images, from scratch)  
**Experiments**: 8 configurations comparing architectures and hyperparameters  
**Expected**: CNNs 85-93%, ViTs 75-87%

```
ViT Architecture: Patch Embedding â†’ Transformer Encoder (Multi-Head Attention + MLP) Ã— 12 â†’ Classification Head
ViT-Tiny: 192 embed_dim, 3 heads, 5.7M params
ViT-Small: 384 embed_dim, 6 heads, 22M params
```

## ğŸ“¦ Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·

### Î ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î±
- Python 3.8+
- CUDA (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ, Î³Î¹Î± GPU acceleration)

### Î’Î®Î¼Î±Ï„Î± Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚

1. ÎšÎ»Ï‰Î½Î¿Ï€Î¿Î¯Î·ÏƒÎ·/Î›Î®ÏˆÎ· Ï„Î¿Ï… project

2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± virtual environment (Ï€ÏÎ¿Ï„ÎµÎ¯Î½ÎµÏ„Î±Î¹):
```bash
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
```

3. Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· dependencies:
```bash
pip install -r requirements.txt
```

## ğŸš€ Î•ÎºÏ„Î­Î»ÎµÏƒÎ·

### Î†ÏƒÎºÎ·ÏƒÎ· #1: CIFAR-100 Vanilla CNN

```bash
# Full experiments (9 experiments, ~9 hours)
python ex1_main_experiments.py

# Quick test (5 epochs, ~10 minutes)
python ex1_main_experiments.py --quick_test

# Single experiment
python ex1_quick_experiment.py --epochs 10 --lr 0.01
```

### Î†ÏƒÎºÎ·ÏƒÎ· #2: Transfer Learning

```bash
# Full experiments (~1-2 hours)
python ex2_transfer_learning_experiments.py

# Quick test (10 epochs)
python ex2_transfer_learning_experiments.py --quick_test

# Single model
python ex2_transfer_learning_experiments.py --single --model resnet18 --epochs 20
```

### Î†ÏƒÎºÎ·ÏƒÎ· #3: Semantic Segmentation

```bash
# Full experiments (~2-3 hours)
python ex3_segmentation_experiments.py

# Quick test (10 epochs, small batch)
python ex3_segmentation_experiments.py --quick_test --batch_size 4

# Single experiment
python ex3_segmentation_experiments.py --single --base_channels 64 --epochs 30
```

### Î†ÏƒÎºÎ·ÏƒÎ· #4: Object Detection

```bash
# Full experiments (8 experiments, ~2-3 hours)
python ex4_detection_experiments.py

# Quick test (3 epochs)
python ex4_detection_experiments.py --quick_test

# Single experiment
python ex4_detection_experiments.py --single --backbone resnet50 --lr 0.005 --epochs 5
```

### Î†ÏƒÎºÎ·ÏƒÎ· #5: Comparative Study (CNN vs Transformer)

```bash
# Full comparative study (8 experiments, ~4-6 hours)
python ex5_comparative_experiments.py

# Quick test (5 epochs)
python ex5_comparative_experiments.py --quick_test

# Single architecture
python ex5_comparative_experiments.py --single --architecture cnn --model resnet18 --epochs 20
python ex5_comparative_experiments.py --single --architecture vit --model tiny --epochs 30
```

## ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±

Î¤Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Î½Ï„Î±Î¹ ÏƒÎµ Î¾ÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„Î¿ÏÏ‚ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚:

```
results_cifar100/           # Î†ÏƒÎºÎ·ÏƒÎ· #1
results_transfer/           # Î†ÏƒÎºÎ·ÏƒÎ· #2
results_segmentation/       # Î†ÏƒÎºÎ·ÏƒÎ· #3
results_detection/          # Î†ÏƒÎºÎ·ÏƒÎ· #4
results_comparative/        # Î†ÏƒÎºÎ·ÏƒÎ· #5
```

ÎšÎ¬Î¸Îµ Ï€ÎµÎ¯ÏÎ±Î¼Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯:
- `results.json` - Metrics ÎºÎ±Î¹ configuration
- `training_curves.png` - Loss & accuracy plots
- `predictions.png` / `detections.png` / `segmentation.png` - Sample results
- `experiments_summary.json` - Î£ÏÎ½Î¿ÏˆÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ experiments
- `comparative_report.txt` - Detailed report (Î†ÏƒÎºÎ·ÏƒÎ· #5)

## ğŸ“ˆ Î‘Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½Î± Benchmarks

| Exercise | Dataset | Metric | Expected |
|----------|---------|--------|----------|
| #1 | CIFAR-100 | Test Accuracy | 30-35% |
| #2 | Oxford Pet | Test Accuracy | 85-92% |
| #3 | SBD | Mean IoU | 40-75% |
| #4 | Oxford Pet | Final Loss | 0.4-0.7 |
| #5 (CNN) | CIFAR-10 | Test Accuracy | 85-93% |
| #5 (ViT) | CIFAR-10 | Test Accuracy | 75-87% |

## ğŸ”§ Î¤ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚

### Î’Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚ Ï€Î¿Ï… Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹

**Core Deep Learning:**
- PyTorch 2.0+ (neural networks, optimization)
- TorchVision (datasets, pretrained models, transforms)

**Data Processing:**
- NumPy (numerical computations, array operations)

**Visualization:**
- Matplotlib (plotting graphs, images)
- Seaborn (enhanced styling)

**Utilities:**
- tqdm (progress bars)

### Datasets

ÎŒÎ»Î± Ï„Î± datasets ÎºÎ±Ï„ÎµÎ²Î±Î¯Î½Î¿Ï…Î½ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±:
- **CIFAR-10/100**: `torchvision.datasets.CIFAR10/100`
- **Oxford Pet**: `torchvision.datasets.OxfordIIITPet`
- **SBD**: Custom loader Î¼Îµ automatic download

### Hardware Requirements

**Minimum:**
- CPU: 4+ cores
- RAM: 8GB
- Disk: 2GB Î³Î¹Î± datasets

**Recommended:**
- GPU: NVIDIA with 4GB+ VRAM (Î³Î¹Î± Î†ÏƒÎºÎ·ÏƒÎ· #5)
- RAM: 16GB
- Disk: 5GB

### Training Times (CPU estimates)

| Exercise | Quick Test | Full Experiments |
|----------|------------|------------------|
| #1 | 10 min | 9 hours |
| #2 | 15 min | 1-2 hours |
| #3 | 30 min | 2-3 hours |
| #4 | 20 min | 2-3 hours |
| #5 | 45 min | 4-6 hours |

## ğŸ“ Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·

Î¤Î¿ project Î±Î½Î±Ï€Ï„ÏÏ‡Î¸Î·ÎºÎµ ÏƒÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï„Î¹Ï‚ Î¿Î´Î·Î³Î¯ÎµÏ‚ Ï„Ï‰Î½ Î±ÏƒÎºÎ®ÏƒÎµÏ‰Î½:

âœ… Î§ÏÎ®ÏƒÎ· PyTorch Î³Î¹Î± deep learning  
âœ… Î§ÏÎ®ÏƒÎ· NumPy Î³Î¹Î± data processing  
âœ… Î§ÏÎ®ÏƒÎ· Matplotlib Î³Î¹Î± visualization  
âœ… ÎŒÎ»ÎµÏ‚ Î¿Î¹ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚ Ï…Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ Î±Ï€ÏŒ Ï„Î·Î½ Î±ÏÏ‡Î® (ÎµÎºÏ„ÏŒÏ‚ pretrained backbones)  
âœ… Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Ï…Ï€ÎµÏ-Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½  
âœ… Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÎºÎ±Î¹ reports

## ğŸ“ Î”Î¿Î¼Î® ÎšÏÎ´Î¹ÎºÎ±

### Unified Utilities (Optimized)

Î¤Î± shared utilities Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎ±Î½ Î³Î¹Î±:
- **Code Reuse**: ÎšÎ¿Î¹Î½Î­Ï‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ training/visualization
- **Consistency**: Î•Î½Î¹Î±Î¯Î¿ API ÏƒÎµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚
- **Maintainability**: Single source of truth

### Trainers

- `ClassificationTrainer`: Î“Î¹Î± Ex1, Ex2, Ex5
- `SegmentationTrainer`: Î“Î¹Î± Ex3 Î¼Îµ IoU metrics
- `DetectionTrainer`: Î“Î¹Î± Ex4 Î¼Îµ Faster R-CNN loss components

### Data Loaders

- `cifar_data_loaders.py`: CIFAR-10 & CIFAR-100 Î¼Îµ configurable augmentation
- `pet_data_loaders.py`: Oxford Pet Î³Î¹Î± classification & detection
- `ex3_sbd_data_loader.py`: SBD Î¼Îµ VOC classes

## ğŸ“ Support

Î“Î¹Î± ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î® Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±, Î±Î½Î±Ï„ÏÎ­Î¾Ï„Îµ ÏƒÏ„Î± comments Î¼Î­ÏƒÎ± ÏƒÏ„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ±.

## ğŸ“„ License

Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÏŒ project Î³Î¹Î± Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ¿ÏÏ‚ ÏƒÎºÎ¿Ï€Î¿ÏÏ‚.
